{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size = 100):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        self.densenet.classifier = nn.Linear(in_features=1024, out_features=1024)\n",
    "        self.embed = nn.Linear(in_features=1024, out_features=embed_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.prelu = nn.ReLU()\n",
    "    def forward(self, images):\n",
    "        densenet_outputs = self.dropout(self.prelu(self.densenet(images)))\n",
    "        embeddings = self.embed(densenet_outputs)\n",
    "        return embeddings\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size=100, hidden_size=128, vocab_size=28, num_layers=1):\n",
    "        \n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=embed_size, hidden_size=hidden_size)\n",
    "        self.fc_out = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
    "        self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embed_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, features, captions):\n",
    "        batch_size = features.size(0)\n",
    "        hidden_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
    "        cell_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
    "        outputs = torch.empty((batch_size, captions.size(1), self.vocab_size)).cuda()\n",
    "        captions_embed = self.embed(captions)\n",
    "        for t in range(captions.size(1)):\n",
    "            if t == 0:\n",
    "                hidden_state, cell_state = self.lstm_cell(features, (hidden_state, cell_state))\n",
    "            else:\n",
    "                hidden_state, cell_state = self.lstm_cell(captions_embed[:, t, :], (hidden_state, cell_state))\n",
    "            out = self.fc_out(hidden_state)\n",
    "            outputs[:, t, :] = out\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"datasets/image/img2smile.csv\")\n",
    "smile=df[\"smile\"].values\n",
    "vocab=set(\"\".join(smile)+\"!E\")\n",
    "index2mol={i:c for i,c in enumerate(vocab)}\n",
    "mol2index={c:i for i,c in enumerate(vocab)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_smiles_tensor(smiles):\n",
    "    \n",
    "    smiles= \"!\"+smiles+\"E\"\n",
    "    smiles_tensor = torch.zeros(len(smiles),len(vocab))\n",
    "    for i,c in enumerate(smiles):\n",
    "        #smiles_tensor[i][mol2index[c]]=1\n",
    "        pass\n",
    "    return smiles_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "5\n",
      "8\n",
      "19\n",
      "21\n",
      "14\n",
      "4\n",
      "4\n",
      "4\n",
      "13\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "14\n",
      "9\n",
      "1\n",
      "18\n",
      "4\n",
      "21\n",
      "6\n",
      "4\n",
      "14\n",
      "9\n",
      "21\n",
      "21\n",
      "9\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "18\n",
      "15\n",
      "14\n",
      "18\n",
      "4\n",
      "4\n",
      "21\n",
      "13\n",
      "4\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "smiles= \"!\"+'[H]N1CCC2(CCC1=O)CN(C1=NN=C(CC)S1)CCN2C'+\"E\"\n",
    "smiles_tensor = torch.zeros(len(smiles),len(vocab))\n",
    "for i,c in enumerate(smiles):\n",
    "    print(mol2index[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tensor[1][10]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 26])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "csv_dir=\"datasets/image/img2smile.csv\"\n",
    "img_dir = \"datasets/image/\"\n",
    "class loaddata(data.Dataset):\n",
    "    def __init__(self,csv_path,img_path,transform=None):\n",
    "        csv_file = pd.read_csv(csv_path)\n",
    "        self.y_train = csv_file[\"smile\"][0:1600].values\n",
    "        self.number =csv_file['imgid'][0:1600].values\n",
    "       # y_test = csv_file[\"smile\"][0:1600].values\n",
    "        self.x_train = os.path.join(img_path,\"train\")\n",
    "       # x_test = os.path.join(img_path,\"train\")\n",
    "        self.transform = transform\n",
    "    def __getitem__(self,index):\n",
    "        img=Image.open(os.path.join(self.x_train,str(self.number[index])+\".png\"))\n",
    "        if self.transform is not None:\n",
    "            x_data = self.transform(img)\n",
    "        smiles = self.y_train[index]\n",
    "        label=make_smiles_tensor(smiles)\n",
    "        \n",
    "        return x_data,label\n",
    "    def __len__(self):\n",
    "        return self.y_train.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "transform_train = transforms.Compose([                        \n",
    "    transforms.RandomResizedCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "train_dataset =loaddata(csv_path=csv_dir,img_path=img_dir,transform=transform_train)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 67 and 47 in dimension 1 at c:\\n\\pytorch_1559129895673\\work\\aten\\src\\th\\generic/THTensorMoreMath.cpp:1307",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-3d3f69776acc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 67 and 47 in dimension 1 at c:\\n\\pytorch_1559129895673\\work\\aten\\src\\th\\generic/THTensorMoreMath.cpp:1307"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[H]N1CCC2(CCC1=O)CN(C1=NN=C(CC)S1)CCN2C'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300 at 0x21F4793AE80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(os.path.join(\"datasets/image/train/\",str(1)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\HPBY/.torch\\models\\densenet121-a639ec97.pth\n",
      "32342954it [01:54, 283074.49it/s] \n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderCNN(embed_size = 100)\n",
    "decoder = DecoderRNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters())+ list(encoder.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    for x,y in train_loader:\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        target =y[:,1:]\n",
    "        train2 = y[:,:y.shape[1]-1]\n",
    "        feature =encoder(x)\n",
    "        output=decoder(feature,train2)\n",
    "        loss =criterion(output.view(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n"
     ]
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get_ipython().run_line_magic('history', '')\n",
      "for line in locals()['In']:\n",
      "    print(line)\n",
      "for line in locals()['In']:\n",
      "    print(line)\n",
      "    history\n",
      "for line in locals()['In']:\n",
      "    print(line)\n",
      "    \n",
      "for line in locals()['In']:\n",
      "    print(line)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for line in locals()['In']:\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
